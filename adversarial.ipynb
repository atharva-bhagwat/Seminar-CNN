{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks import BasicIterativeMethod\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "\n",
    "# Set the matplotlib figure size\n",
    "plt.rc('figure', figsize = (12.0, 12.0))\n",
    "\n",
    "# Set the learning phase to false, the model is pre-trained.\n",
    "backend.set_learning_phase(False)\n",
    "keras_model = load_model('models/cnnmodel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 27\n",
    "\n",
    "raw_data = pd.read_csv(\"input/train.csv\")\n",
    "train, validate = train_test_split(raw_data, \n",
    "                                   test_size=0.1,\n",
    "                                   random_state = seed, \n",
    "                                   stratify = raw_data['label'])\n",
    "\n",
    "# Split into input (X) and output (Y) variables\n",
    "x_validation = validate.values[:,1:].reshape(4200,28,28, 1)\n",
    "y_validation = validate.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normal validation accuracy is: 0.9938095238095238\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(1234)\n",
    "\n",
    "if keras.backend.image_dim_ordering() != 'tf':\n",
    "    keras.backend.set_image_dim_ordering('tf')\n",
    "    print(\"INFO: '~/.keras/keras.json' sets 'image_dim_ordering' to \"\n",
    "          \"'th', temporarily setting to 'tf'\")\n",
    "\n",
    "# Retrieve the tensorflow session\n",
    "sess =  backend.get_session()\n",
    "\n",
    "# Define input TF placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "# Evaluate the model's accuracy on the validation data used in training\n",
    "x_validation = x_validation.astype('float32')\n",
    "x_validation /= 255\n",
    "\n",
    "pred = np.argmax(keras_model.predict(x_validation), axis = 1)\n",
    "acc =  np.mean(np.equal(pred, y_validation))\n",
    "\n",
    "print(\"The normal validation accuracy is: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-03-27 13:12:28,082 cleverhans] Constructing new graph for attack FastGradientMethod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adversarial validation accuracy is: 0.0988095238095238\n"
     ]
    }
   ],
   "source": [
    "wrap = KerasModelWrapper(keras_model)\n",
    "fgsm = FastGradientMethod(wrap, sess=sess)\n",
    "fgsm_params = {'eps': 0.3,\n",
    "               'clip_min': 0.,\n",
    "               'clip_max': 1.}\n",
    "adv_x = fgsm.generate_np(x_validation, **fgsm_params)\n",
    "\n",
    "adv_pred = np.argmax(keras_model.predict(adv_x), axis = 1)\n",
    "adv_acc =  np.mean(np.equal(adv_pred, y_validation))\n",
    "\n",
    "print(\"The adversarial validation accuracy is: {}\".format(adv_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stitch_images(images, y_img_count, x_img_count, margin = 2):\n",
    "    \n",
    "    # Dimensions of the images\n",
    "    img_width = images[0].shape[0]\n",
    "    img_height = images[0].shape[1]\n",
    "    \n",
    "    width = y_img_count * img_width + (y_img_count - 1) * margin\n",
    "    height = x_img_count * img_height + (x_img_count - 1) * margin\n",
    "    stitched_images = np.zeros((width, height, 3))\n",
    "\n",
    "    # Fill the picture with our saved filters\n",
    "    for i in range(y_img_count):\n",
    "        for j in range(x_img_count):\n",
    "            img = images[i * x_img_count + j]\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.dstack([img] * 3)\n",
    "            stitched_images[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                            (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "    return stitched_images\n",
    "\n",
    "x_sample = x_validation[0].reshape(28, 28)\n",
    "adv_x_sample = adv_x[0].reshape(28, 28)\n",
    "\n",
    "adv_comparison = stitch_images([x_sample, adv_x_sample], 1, 2)\n",
    "\n",
    "plt.imshow(adv_comparison)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normal digit is predicted to be a [7]\n",
      "The adversarial example digit is predicted to be an [2]\n"
     ]
    }
   ],
   "source": [
    "normal_digit_img = x_sample.reshape(1, 28, 28, 1)\n",
    "adv_digit_img = adv_x_sample.reshape(1, 28, 28, 1)\n",
    "\n",
    "normal_digit_pred = np.argmax(keras_model.predict(normal_digit_img), axis = 1)\n",
    "adv_digit_pred = np.argmax(keras_model.predict(adv_digit_img), axis = 1)\n",
    "\n",
    "print('The normal digit is predicted to be a {}'.format(normal_digit_pred))\n",
    "print('The adversarial example digit is predicted to be an {}'.format(adv_digit_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
